{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "xml_paths = glob(\"object_detection_datas/train/**/*.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def recursive_parse_xml_to_dict(xml):\n",
    "  if not xml:\n",
    "    return {xml.tag: xml.text}\n",
    "  result = {}\n",
    "  for child in xml:\n",
    "    child_result = recursive_parse_xml_to_dict(child)\n",
    "    if child.tag != 'object':\n",
    "      result[child.tag] = child_result[child.tag]\n",
    "    else:\n",
    "      if child.tag not in result:\n",
    "        result[child.tag] = []\n",
    "      result[child.tag].append(child_result[child.tag])\n",
    "  return {xml.tag: result}\n",
    "\n",
    "def dict_to_tf_example(data,\n",
    "                       dataset_directory,\n",
    "                       label_map_dict,\n",
    "                       ignore_difficult_instances=False,\n",
    "                       image_subdirectory='JPEGImages'):\n",
    "  \"\"\"Convert XML derived dict to tf.Example proto.\n",
    "  Notice that this function normalizes the bounding box coordinates provided\n",
    "  by the raw data.\n",
    "  Args:\n",
    "    data: dict holding PASCAL XML fields for a single image (obtained by\n",
    "      running dataset_util.recursive_parse_xml_to_dict)\n",
    "    dataset_directory: Path to root directory holding PASCAL dataset\n",
    "    label_map_dict: A map from string label names to integers ids.\n",
    "    ignore_difficult_instances: Whether to skip difficult instances in the\n",
    "      dataset  (default: False).\n",
    "    image_subdirectory: String specifying subdirectory within the\n",
    "      PASCAL dataset directory holding the actual image data.\n",
    "  Returns:\n",
    "    example: The converted tf.Example.\n",
    "  Raises:\n",
    "    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n",
    "  \"\"\"\n",
    "  img_path = os.path.join(data['folder'], image_subdirectory, data['filename'])\n",
    "  full_path = os.path.join(dataset_directory, img_path)\n",
    "  with tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "  image = PIL.Image.open(encoded_jpg_io)\n",
    "  if image.format != 'JPEG':\n",
    "    raise ValueError('Image format not JPEG')\n",
    "  key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "  width = int(data['size']['width'])\n",
    "  height = int(data['size']['height'])\n",
    "\n",
    "  xmin = []\n",
    "  ymin = []\n",
    "  xmax = []\n",
    "  ymax = []\n",
    "  classes = []\n",
    "  classes_text = []\n",
    "  truncated = []\n",
    "  poses = []\n",
    "  difficult_obj = []\n",
    "  if 'object' in data:\n",
    "    for obj in data['object']:\n",
    "      difficult = bool(int(obj['difficult']))\n",
    "      if ignore_difficult_instances and difficult:\n",
    "        continue\n",
    "\n",
    "      difficult_obj.append(int(difficult))\n",
    "\n",
    "      xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "      ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "      xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "      ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "      classes_text.append(obj['name'].encode('utf8'))\n",
    "      classes.append(label_map_dict[obj['name']])\n",
    "      truncated.append(int(obj['truncated']))\n",
    "      poses.append(obj['pose'].encode('utf8'))\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "      'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "      'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "      'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "  }))\n",
    "  return example\n",
    "\n",
    "def get_label_map_dict(label_map_path_or_proto,\n",
    "                       use_display_name=False,\n",
    "                       fill_in_gaps_and_background=False):\n",
    "  \"\"\"Reads a label map and returns a dictionary of label names to id.\n",
    "  Args:\n",
    "    label_map_path_or_proto: path to StringIntLabelMap proto text file or the\n",
    "      proto itself.\n",
    "    use_display_name: whether to use the label map items' display names as keys.\n",
    "    fill_in_gaps_and_background: whether to fill in gaps and background with\n",
    "    respect to the id field in the proto. The id: 0 is reserved for the\n",
    "    'background' class and will be added if it is missing. All other missing\n",
    "    ids in range(1, max(id)) will be added with a dummy class name\n",
    "    (\"class_<id>\") if they are missing.\n",
    "  Returns:\n",
    "    A dictionary mapping label names to id.\n",
    "  Raises:\n",
    "    ValueError: if fill_in_gaps_and_background and label_map has non-integer or\n",
    "    negative values.\n",
    "  \"\"\"\n",
    "  if isinstance(label_map_path_or_proto, string_types):\n",
    "    label_map = load_labelmap(label_map_path_or_proto)\n",
    "  else:\n",
    "    _validate_label_map(label_map_path_or_proto)\n",
    "    label_map = label_map_path_or_proto\n",
    "\n",
    "  label_map_dict = {}\n",
    "  for item in label_map.item:\n",
    "    if use_display_name:\n",
    "      label_map_dict[item.display_name] = item.id\n",
    "    else:\n",
    "      label_map_dict[item.name] = item.id\n",
    "\n",
    "  if fill_in_gaps_and_background:\n",
    "    values = set(label_map_dict.values())\n",
    "\n",
    "    if 0 not in values:\n",
    "      label_map_dict['background'] = 0\n",
    "    if not all(isinstance(value, int) for value in values):\n",
    "      raise ValueError('The values in label map must be integers in order to'\n",
    "                       'fill_in_gaps_and_background.')\n",
    "    if not all(value >= 0 for value in values):\n",
    "      raise ValueError('The values in the label map must be positive.')\n",
    "\n",
    "    if len(values) != max(values) + 1:\n",
    "      # there are gaps in the labels, fill in gaps.\n",
    "      for value in range(1, max(values)):\n",
    "        if value not in values:\n",
    "          # TODO(rathodv): Add a prefix 'class_' here once the tool to generate\n",
    "          # teacher annotation adds this prefix in the data.\n",
    "          label_map_dict[str(value)] = value\n",
    "\n",
    "  return label_map_dict\n",
    "\n",
    "def load_labelmap(path):\n",
    "  \"\"\"Loads label map proto.\n",
    "  Args:\n",
    "    path: path to StringIntLabelMap proto text file.\n",
    "  Returns:\n",
    "    a StringIntLabelMapProto\n",
    "  \"\"\"\n",
    "  with tf.gfile.GFile(path, 'r') as fid:\n",
    "    label_map_string = fid.read()\n",
    "    label_map = string_int_label_map_pb2.StringIntLabelMap()\n",
    "    try:\n",
    "      text_format.Merge(label_map_string, label_map)\n",
    "    except text_format.ParseError:\n",
    "      label_map.ParseFromString(label_map_string)\n",
    "  _validate_label_map(label_map)\n",
    "  return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmo/Downloads/my_envs/tf1.15-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from lxml import etree\n",
    "import os, io, PIL, hashlib\n",
    "from six import string_types\n",
    "import dataset_util\n",
    "\n",
    "label_map_path = './label_map.pbtxt'\n",
    "label_map_dict = {}\n",
    "label_map_dict['so_khung'] = 1\n",
    "label_map_dict['nhan_hieu'] = 2\n",
    "label_map_dict['so_may'] = 3\n",
    "label_map_dict['ho_ten'] = 4\n",
    "label_map_dict['noi_cap'] = 5\n",
    "label_map_dict['bien_so'] = 6\n",
    "label_map_dict['loai_xe'] = 7\n",
    "label_map_dict['dia_chi'] = 8\n",
    "label_map_dict['so_DKX'] = 9\n",
    "label_map_dict['ngay_cap'] = 10\n",
    "\n",
    "tfrecord_path = \"./test.tfrecord\"\n",
    "xml_paths = glob(\"object_detection_datas/val/**/*.xml\")\n",
    "image_dir = \"./\"\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(tfrecord_path)\n",
    "for idx, path in enumerate(xml_paths):\n",
    "    with tf.gfile.GFile(path, 'r') as fid:\n",
    "        xml_str = fid.read()\n",
    "    xml = etree.fromstring(xml_str)\n",
    "    data = recursive_parse_xml_to_dict(xml)['annotation']\n",
    "    data['folder'] = \"\"\n",
    "    data['filename'] = path.split('.')[0] + '.jpg'\n",
    "    tf_example = dict_to_tf_example(data, image_dir, label_map_dict, image_subdirectory='')\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for _ in tf.python_io.tf_record_iterator('train.tfrecord'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1_15",
   "language": "python",
   "name": "tf1_15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
